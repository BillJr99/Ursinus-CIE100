---
layout: assignment
permalink: Assignments/CodedBias
title: "CIE100: Common Intellectual Experience - Coded Bias Reflection"
excerpt: "CIE100: Common Intellectual Experience - Coded Bias Reflection"

info:
  coursenum: CIE100
  points: 10
  goals:
    - To apply the Ursinus questions to the STEM disciplines
    - To identify potential challenges in automated intelligent computing systems and risks to vulnerable populations
    - To envision a more careful and responsible evolution and application of Artificial Intelligence

  readings:
    - rlink: "https://www.youtube.com/watch?v=Ok5sKLXqynQ&list=PLJ8cMiYb3G5cOFj1VQf8ykNOI0ptuHybc&index=4"
      rtitle: "Are We Automating Racism?"

---

The documentary [Coded Bias](https://www.codedbias.com/) and the video [Are We Automating Racism?](https://www.youtube.com/watch?v=Ok5sKLXqynQ&list=PLJ8cMiYb3G5cOFj1VQf8ykNOI0ptuHybc&index=4) examine the implicit biases in artificial intelligence (AI) and machine learning.  Often, these biases result from the use of "training data" that AI uses to learn patterns.  These biases are then amplified through the automated decisions the system makes when presented with new scenarios.  Sometimes, the developers are unaware that these historical biases existed and manifested in the training data they use; often, it is difficult to scrutinize the automated system because it does not necessarily justify its decisions or its rationale.  

In this reflection, please comment on the extent to which you believe AI could be responsibly deployed to avoid, mitigate, and audit for potential harms.  Do you think it is more likely that the AI will harm people directly, or, rather, will the people interpreting the decisions made by AI present a greater risk?  Have you experienced bias from automated systems in your own life?  How can technologists better ensure that their systems mitigate these risks prior to deployment?  Cite at least two examples (at least one each from *Coded Bias* and from *Are We Automating Racism?*) in your discussion.

Consider the [Ursinus Questions](https://www.ursinus.edu/quest/the-questions/).  Organize your reflection with one section dedicated to each question.  Here are a few prompts to consider for each section (however, you are welcome to come up with your own instead!):

1. **Understanding Bias in AI (Ursinus Question: What should matter to me?):**
   - Analyze the biases depicted in both "Coded Bias" and "Are We Automating Racism." How do these biases manifest in AI systems, and why should they matter to individuals, communities, and society at large?
   - Identify the potential challenges and risks these biases pose to vulnerable populations. How might they exacerbate existing inequalities and injustices?

2. **Transparency, Accountability, and Social Justice (Ursinus Question: How should we live together?):**
   - Evaluate the ethical considerations of transparency and accountability in AI. How do these principles contribute to social justice and communal harmony?
   - Discuss the role of regulation, industry standards, and community engagement in ensuring responsible AI practices. What collaborative efforts are needed to foster ethical AI development?

3. **Human-Centric Computing and Automation (Ursinus Question: How can we understand the world?):**
   - Reflect on the balance between human judgment and automated decision-making. How can human-centric computing principles guide the design and deployment of AI systems?
   - Consider the video's question, "Are We Automating Racism?" What are the implications of automating human biases, and how can we mitigate these risks?

4. **Envisioning Responsible AI (Ursinus Question: What will I do?):**
   - Envision a future where AI is developed and applied with care and responsibility. What steps must be taken by researchers, policymakers, educators, and industry leaders to achieve this vision?
   - Propose interdisciplinary solutions that address the challenges and risks highlighted in both the documentary and the video. How can we ensure that AI serves the greater good without compromising ethical values and social equity?